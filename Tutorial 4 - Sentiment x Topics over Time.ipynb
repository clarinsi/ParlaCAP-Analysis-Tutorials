{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6778b9a",
   "metadata": {},
   "source": [
    "### Tutorial 4 - Sentiment & Frequency of Topics over Time\n",
    "\n",
    "In the previous tutorials, we explored **what topics are discussed in different parliaments** and **how positively or negatively they are discussed**. We also learned how to compare countries using cosine distances to see which parliaments are most similar in sentiment or topic focus.\n",
    "\n",
    "In this tutorial, we take a closer look at **how these patterns change over time**. Specifically, we will:\n",
    "- **Load and read the datasets**\n",
    "- **Select a timeframe**\n",
    "- **Calculate and visualize sentiment over time for one selected country (e.g. RS)**\n",
    "    1) across **all topics**\n",
    "    2) for **one specific topic** (e.g. 'Health')\n",
    "- **Analyze average sentiment scores by country and CAP category** using heatmaps\n",
    "- **Avg. weekly word count**, which reflect parliamentary attention\n",
    "    - across selected countries (e.g. RS, HU, HR) for one chosen topic (e.g. 'Health')\n",
    "\n",
    "This approach allows us to answer questions such as:\n",
    "- *Are there changes in sentiment across CAP categories over time in the Serbian parliament?*\n",
    "- *Did sentiment change noticeably during known impactful events, like COVID outbreak, in Serbia?*\n",
    "- *How does the sentiment change towards 'Health' differ in parliamentary debates in Serbia (RS), Croatia (HR) and Hungary (HU)?* \n",
    "- *How did attention to 'Health' evolve in Serbia, Hungary and Croatia? Are there noticeable patterns in weekly word count that suggest changes in parliamentary activity?*\n",
    "\n",
    "We will approach these questions using **time series analysis**, a method that lets us track trends over regular intervals (e.g. weekly). For example, we can calculate the **average sentiment per week** for each country or for a specific topic. This allows us to see not just the overall sentiment, but also **when peaks or dips occur**, which may correspond to political events, crises or debates. \n",
    "\n",
    "In a similar way, we will compute **weekly word counts** by CAP category, which helps us understand **how much attention parliaments devote to each topic over time**. By plotting these trends as heatmaps, we can quickly identify **patterns or shifts in focus** both for individual countries and across all countries. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c572a37f",
   "metadata": {},
   "source": [
    "**1. Setup & Data Loading**\n",
    "\n",
    "This setup (installing/importing) libraries and data loading & filtering steps are the **same as in Tutorial 1**. For detailed explanations, see **Tutorial 1, Sections 1-2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97890473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following line if you haven't installed pandas yet\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165fa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aaaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set consistent style\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. First, we have to increase the CSV field size limit ----\n",
    "max_int = 2**31 - 1\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(max_int)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        max_int = max_int // 10\n",
    "\n",
    "countries = [\"AT\", \"BA\", \"BE\", \"BG\", \"CZ\", \"DK\", \"EE\", \"ES\", \"ES-CT\", \"ES-GA\", \"ES-PV\",\n",
    "             \"FR\", \"GB\", \"GR\", \"HR\", \"HU\", \"IS\", \"IT\", \"LV\",\n",
    "             \"NL\", \"NO\", \"PL\", \"PT\", \"RS\", \"SE\", \"SI\", \"TR\", \"UA\"] #change country codes according to your available datasets\n",
    "\n",
    "base_dir = Path().resolve()\n",
    "\n",
    "# ---- 2. Choose what columns to read (including CAP and sentiment columns) ----\n",
    "cols_to_keep = [\n",
    "    \"id\", \"date\", \"lang_code\", \"lang\", \"speaker_role\", \"speaker_MP\",\n",
    "    \"speaker_minister\", \"speaker_party\", \"speaker_party_name\", \"party_status\",\n",
    "    \"party_orientation\", \"speaker_id\", \"speaker_name\", \"speaker_gender\",\n",
    "    \"speaker_birth\", \"word_count\", \"CAP_category\", \"sent3_category\", \"sent6_category\", \"sent_logit\"\n",
    "]\n",
    "\n",
    "# ---- 3. Define dtypes to reduce memory ----\n",
    "dtypes = {\n",
    "    \"id\": str,\n",
    "    \"date\": str,\n",
    "    \"lang_code\": \"category\",\n",
    "    \"lang\": \"category\",\n",
    "    \"speaker_role\": \"category\",\n",
    "    \"speaker_MP\": \"category\",\n",
    "    \"speaker_minister\": \"category\",\n",
    "    \"speaker_party\": \"category\",\n",
    "    \"speaker_party_name\": \"category\",\n",
    "    \"party_status\": \"category\",\n",
    "    \"party_orientation\": \"category\",\n",
    "    \"speaker_id\": \"category\",\n",
    "    \"speaker_name\": \"category\",\n",
    "    \"speaker_gender\": \"category\",\n",
    "    \"speaker_birth\": \"Int32\",\n",
    "    \"word_count\": \"Int32\",\n",
    "    \"CAP_category\": \"category\",\n",
    "    \"sent3_category\": \"category\",\n",
    "    \"sent6_category\": \"category\",\n",
    "    \"sent_logit\": \"float32\"\n",
    "}\n",
    "\n",
    "# ---- 4. Create lists to accumulate filtered chunks ----\n",
    "all_chunks = []\n",
    "\n",
    "for country in countries:\n",
    "    file_path = base_dir / f\"ParlaMint-{country}_processed_no_text.tsv\"\n",
    "\n",
    "    # --- 4.1. Read in chunks using pandas.read_csv ----\n",
    "    for chunk in pd.read_csv(file_path, sep=\"\\t\", usecols=cols_to_keep,\n",
    "                             dtype=dtypes, chunksize=50_000, engine=\"python\"):\n",
    "        chunk[\"country\"] = country\n",
    "        chunk[\"country\"] = chunk[\"country\"].astype(\"category\")\n",
    "\n",
    "        # ---- 4.2. Filter MPs with regular role ----\n",
    "        filtered_chunk = chunk.query(\"speaker_MP == 'MP' and speaker_role == 'Regular'\")\n",
    "\n",
    "        # ---- 4.3. Drop rows where CAP_category or sentiment is empty ----\n",
    "        filtered_chunk = filtered_chunk[\n",
    "            filtered_chunk[\"CAP_category\"].notna() & (filtered_chunk[\"CAP_category\"] != \"\") &\n",
    "            filtered_chunk[\"sent3_category\"].notna() & (filtered_chunk[\"sent3_category\"] != \"\") &\n",
    "            filtered_chunk[\"sent6_category\"].notna() & (filtered_chunk[\"sent6_category\"] != \"\")\n",
    "        ]\n",
    "\n",
    "        # ---- 4.4. Accumulate filtered chunks ----\n",
    "        if not filtered_chunk.empty:\n",
    "            all_chunks.append(filtered_chunk)\n",
    "\n",
    "# ---- 5. Concatenate all accumulated chunks into DataFrames ----\n",
    "filtered_all = pd.concat(all_chunks, ignore_index=True)\n",
    "del all_chunks\n",
    "print(\"All filtered:\", filtered_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7487a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_all[\"CAP_category\"] = filtered_all[\"CAP_category\"].astype(\"category\")\n",
    "filtered_all = filtered_all[~filtered_all[\"CAP_category\"].isin([\"Mix\", \"Other\"])]\n",
    "filtered_all[\"CAP_category\"] = filtered_all[\"CAP_category\"].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea34857",
   "metadata": {},
   "source": [
    "**2. Time Range Analysis**\n",
    "\n",
    "Before analyzing sentiment or topic frequency, it's important to **know the time span of our data**. Each country's dataset covers different periods and some dates might be missing. By converting the date column in our DataFrame *filtered_all* to a **datetime obect**, we make sure that Python can handle the dates properly. \n",
    "\n",
    "After parsing through the converted dates in our DataFrame, we can check the **earliest and latest speech for each country** and identify the **overlapping period** that is common across all countries. Knowing the overlapping range can help us keep our later cross-country comparisons **fair and meaningful** because we will compare the same time frame where we have valid data for all parliaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Make sure the date in the dataset is parsed to datetime ----\n",
    "filtered_all[\"date\"] = pd.to_datetime(filtered_all[\"date\"], errors=\"coerce\")\n",
    "filtered_all = filtered_all.dropna(subset=[\"date\"])\n",
    "\n",
    "countries = filtered_all[\"country\"].unique().tolist()\n",
    "\n",
    "min_dates = []\n",
    "max_dates = []\n",
    "\n",
    "for country in countries:\n",
    "    df_country = filtered_all[filtered_all[\"country\"] == country]\n",
    "\n",
    "    min_date = df_country[\"date\"].min()\n",
    "    max_date = df_country[\"date\"].max()\n",
    "\n",
    "    min_dates.append(min_date)\n",
    "    max_dates.append(max_date)\n",
    "\n",
    "    # ---- 1.1. Print per-country ranges ----\n",
    "    print(f\"{country}: from {min_date.date()} to {max_date.date()}\")\n",
    "\n",
    "# ---- 2. Get overlappin range across all countries ----\n",
    "latest_min_date = max(min_dates)\n",
    "earliest_max_date = min(max_dates)\n",
    "\n",
    "print(f\"\\nOverlapping date range across all countries: {latest_min_date.date()} to {earliest_max_date.date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746592e3",
   "metadata": {},
   "source": [
    "**3. Group data by time**\n",
    "\n",
    "Now that we know the overlapping date range across all countries, we can **focus our analysis on a specific time frame**. You have two options:\n",
    "1) Use the **overlapping time frame** that we identified in **Section 2**.\n",
    "2) Select a **custom time frame** of your choice, if you want to zoom in on specific events or months.\n",
    "\n",
    "The code below lets you define a custom start and end date, and then filters the dataset to only include speeches within this period.\n",
    "\n",
    "*Note: If you want to change the date range for a later analysis, you can simply **copy the two next code blocks below**, modify the values of 'custom_start', 'custom_end', and rename the filtered data to a new variable, like 'filtered_all_custom2', to avoid overwriting the previous filtered dataset. Then run the grouping step code on that new dataset ('filtered_all_custom2'). This way, you can run multiple analyses on different time frames without affecting earlier results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Define a date range ----\n",
    "custom_start = pd.to_datetime(\"2020-02-14\") # <-- change to whatever you want\n",
    "custom_end = pd.to_datetime(\"2022-02-14\")   # <-- change to whatever you want\n",
    "\n",
    "filtered_all_custom = filtered_all[\n",
    "    (filtered_all[\"date\"] >= custom_start) &\n",
    "    (filtered_all[\"date\"] <= custom_end)\n",
    "]\n",
    "\n",
    "print(f\"Original speeches: {len(filtered_all):,}\")\n",
    "print(f\"Filtered speeches (from {custom_start.date()} to {custom_end.date()}): {len(filtered_all_custom):,}\")\n",
    "\n",
    "print(\"Date range in filtered data:\",\n",
    "      filtered_all_custom['date'].min().date(),\n",
    "      \"to\",\n",
    "      filtered_all_custom['date'].max().date())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78423c59",
   "metadata": {},
   "source": [
    "**3.1. Groupin speeches by country, topic and week**\n",
    "\n",
    "Now that we have a dataset filtered to our chosen time frame, we can **organize the speeches by country and CAP category** and summarize them on a **weekly basis**. With the resulting DataFrame, we can then calculate **total words** spoken per country-topic-week and **average sentiment** per country-topic-week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Group by country, CAP category and month ----\n",
    "grouped = (\n",
    "    filtered_all_custom\n",
    "    .groupby(\n",
    "        [\"country\", \"CAP_category\", pd.Grouper(key=\"date\", freq=\"W\")]\n",
    "    )\n",
    "    .agg(\n",
    "        total_words=pd.NamedAgg(column=\"word_count\", aggfunc=\"sum\"),    #sum up words per group\n",
    "        mean_sent=pd.NamedAgg(column=\"sent_logit\", aggfunc=\"mean\")      # average sentiment\n",
    "    )\n",
    ")\n",
    "\n",
    "# ---- 2. Put results in a DataFrame ----\n",
    "grouped_df = grouped.reset_index()\n",
    "\n",
    "# ---- 2.1. Print the first 10 rows of the DataFrame \"grouped\" ----\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659ebae",
   "metadata": {},
   "source": [
    "*Looking at the first 10 rows of our grouped data, we can see that each row represents now a **specific country, CAP category and week**. The columns show:*\n",
    "- *'total_words': the total number of words spoken in that country about that CAP category during that week.*\n",
    "- *'mean_sent': the average sentiment score of the speeches for that country-topic-week.*\n",
    "\n",
    "*Note: Weeks with 'total_words = 0' are gaps in the data for that topic. Also, we should interpret the 'NaN' values in 'mean_sent' as 'no speeches to measure sentiment'. When visualizing trends over time, these gaps can appear as missing values or blank cells in heatmaps.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1eda7",
   "metadata": {},
   "source": [
    "**4. Changes in sentiment across CAP categories over time. Example: Serbia (RS)**\n",
    "\n",
    "Now that we have filtered the speeches to a specific time frame and grouped them by week, we can narrow our analysis to **one country** to see detailed patterns in sentiment across different topics. \n",
    "\n",
    "The question **Which CAP categories in Serbia (RS) show the most positive or negative sentiment over time?** was chosen because it allows us to **zoom in on a single country** and examine the **emotional tone of parliamentary discussions at a more granular level**. By focusing on one parliament we can **identify topic-specific trends** (categories that have consistently more pos. or neg. sentiment), **spot temporal dynamics** (spikes or drops that might correspond to important events) and **highlight outliers or unusual patterns**. \n",
    "\n",
    "*Note: As the overall time frame, we chose the two most recent years in the available data for RS (14.02.2020 - 14.02.2022) which also cover the first couple of months of the COVID outbreak.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Choose a target country ----\n",
    "target_country = \"RS\"  # Change this to any country code: \"DE\", \"IT\", \"GB\", etc.\n",
    "\n",
    "# ---- 2. Filter for the country and ensure date is datetime ----\n",
    "country_df = filtered_all_custom[filtered_all_custom['country'] == target_country].copy()\n",
    "country_df['date'] = pd.to_datetime(country_df['date'])\n",
    "country_df['week'] = country_df['date'].dt.to_period('W').astype(str) # Create a 'week' period column\n",
    "\n",
    "# ---- 3. Group by Week and CAP Category, calculate mean sentiment ----\n",
    "weekly_sentiment = country_df.groupby(['week', 'CAP_category'])['sent_logit'].mean().reset_index()\n",
    "\n",
    "# ---- 4. Pivot the table: Weeks as rows, CAP Categories as columns ----\n",
    "heatmap_data_country = weekly_sentiment.pivot(index='week', columns='CAP_category', values='sent_logit')\n",
    "\n",
    "# ---- 5. Plot the heatmap ----\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "sns.heatmap(\n",
    "    heatmap_data_country.T,\n",
    "    cmap=\"RdYlGn\",\n",
    "    cbar_kws={\"label\": \"Average Sentiment (logit)\", \"shrink\": 0.8},\n",
    "    square=False\n",
    ")\n",
    "\n",
    "plt.title(f'Fig. 1, Weekly Average Sentiment per Topic - {target_country}, {custom_start} - {custom_end}\\n(Green = More Positive, Red = More Negative)', fontsize=14, pad=20)\n",
    "plt.xlabel(\"Week\", fontsize=12)\n",
    "plt.ylabel(\"CAP Category\", fontsize=12)\n",
    "plt.xticks(rotation=90, ha='center', fontsize=7)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e78fd",
   "metadata": {},
   "source": [
    "*Figure 1, visualized the **weekly average sentiment** of parliamentary debates across all **21 major policy topics** over a two-year period. The key finding is that sentiment across almost all topics was significantly more negative in **early 2020**, which also marks the onset of the COVID-19 pandemic. This drop in sentiment across topics is followed by cluster of missing data for majority of topics, indicating that the parliament might have been in lockdown too (similar gaps can also visible during the official summer breaks of a parliament) or focused much more on a few topics like 'Government Operations' as a reaction to the COVID outbreak.*\n",
    "\n",
    "*Connected to that, the 'Health' topic shows one of the most dramatic and sustained negative shifts. It turns dark red and stays predominantly negative for the entire period. This could reflect the ongoing crisis. Economy-related topics, such as 'Macroeconomics' or 'Social Welfare' also show strong negative reactions which could indicate the economic uncertainty of the early pandemic. 'Government Operations' also turns very red in this period.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a017c4",
   "metadata": {},
   "source": [
    "**4.1. Time series for a specific top (Example: Serbia (RS))**\n",
    "\n",
    "Figure 1 shows sentiment across all topics in the selected country (Serbia), highlighting general trends. To get a clearer overview of topic-specific dynamics over time (and for better readibility of the dates), we can examine the weekly sentiment for one chosen CAP category.\n",
    "\n",
    "In the following part, 'Health' was chosen because it showed one of the most pronounced sentiment shifts durint the chosen time period, reflecting the parliament's response to the COVID-19 outbreak.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32568220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Choose target country and CAP category ----\n",
    "target_country = \"RS\"\n",
    "category = \"Health\"\n",
    "\n",
    "# ---- 2. Filter the dataset for the selected country and category ----\n",
    "category_df = filtered_all_custom[\n",
    "    (filtered_all_custom[\"country\"] == target_country) &\n",
    "    (filtered_all_custom[\"CAP_category\"] == category)\n",
    "].copy()\n",
    "\n",
    "# ---- 3. Group by week and calculate mean sentiment ----\n",
    "category_over_time = (\n",
    "    category_df\n",
    "    .groupby([pd.Grouper(key=\"date\", freq=\"W\")])\n",
    "    .agg(mean_sent=(\"sent_logit\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ---- 4. Make sure 'date' is datetime and create week period ----\n",
    "category_over_time[\"date\"] = pd.to_datetime(category_over_time[\"date\"], errors=\"coerce\")\n",
    "category_over_time[\"week\"] = category_over_time[\"date\"].dt.to_period(\"W\").astype(str)\n",
    "\n",
    "# ---- 5. Pivot the data to have weeks as columns ----\n",
    "# Use a constant string for the row since we only have one CAP category\n",
    "heatmap_data = category_over_time.pivot_table(\n",
    "    index=[pd.Series([category]*len(category_over_time), name=\"CAP_category\")],\n",
    "    columns=\"week\",\n",
    "    values=\"mean_sent\",\n",
    "    aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "# ---- 6. Plot Heatmap ----\n",
    "plt.figure(figsize=(14, 4))  # smaller height since only one row\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"RdYlGn\",\n",
    "    vmin=0,\n",
    "    vmax=4.5,\n",
    "    annot=False,\n",
    "    cbar_kws={'label':'Mean Sentiment'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray'\n",
    ")\n",
    "plt.title(f\"Fig. 2, Weekly Average Sentiment — {category} in {target_country}, {custom_start} - {custom_end}\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"CAP Category\")\n",
    "plt.xticks(rotation=90, ha=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845f54d",
   "metadata": {},
   "source": [
    "*Figure 2 displays a concise overview of the weekly avg. sentiment of the Serbian parliament regarding all speeches related to 'Health'. We can see a sharp and lasting negative shift at the beginning of our chosen time frame (March 2020), coinciding with the outbreak of COVID-19. After this initial crash, the 'Health' topic remains largely negative, with a particular sharp drop in May 2021, followed by a noticeable rebound in the weeks that followed. To investigate whether there were events causing the sentiment spike, one could examine **concordances** of the speeches - but that would go beyond the scope of this tutorial.*\n",
    "\n",
    "At the same time, this approach can also be flipped around: if you want to explore how specific events (e.g. elections, protests, war etc.) influenced the emotional tone of debates in parliament, you can simply choose a CAP category and trace how its sentiment shifted over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59a3a7",
   "metadata": {},
   "source": [
    "**4.2 How does the sentiment change towards 'Health' differ in parliamentary debates in RS, (HR) and (HU)? (cross-country comparison)**\n",
    "\n",
    "So far, we have explored sentiment within Serbia's parliament to understand how debates on 'Health' evolved over time. While this shows the internal dynamics of one country, it doesn't tell us whether similar shifts occurred elsewhere. To put Serbia's trajectory into context, we can compare it with neighboring countries like **Croatia (HR)** and **Hungary (HU)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Choose the CAP category you want to focus on ----\n",
    "category = \"Health\"\n",
    "\n",
    "# ---- 2. Filter dataset for the category and selected countries ----\n",
    "countries_to_compare = [\"RS\", \"HR\", \"HU\"]\n",
    "category_df = filtered_all_custom[\n",
    "    (filtered_all_custom[\"CAP_category\"] == category) &\n",
    "    (filtered_all_custom[\"country\"].isin(countries_to_compare))\n",
    "].copy()\n",
    "\n",
    "# ---- 3. Ensure 'date' is datetime and create a 'week' column ----\n",
    "category_df[\"date\"] = pd.to_datetime(category_df[\"date\"], errors=\"coerce\")\n",
    "category_df[\"week\"] = category_df[\"date\"].dt.to_period(\"W\").dt.start_time  # first day of the week\n",
    "\n",
    "# ---- 4. Group by country + week and calculate mean sentiment ----\n",
    "weekly_sentiment = (\n",
    "    category_df\n",
    "    .groupby([\"country\", \"week\"])\n",
    "    .agg(mean_sent=(\"sent_logit\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ---- 5. Plot Heatmap ----\n",
    "# Pivot to have countries as rows, weeks as columns\n",
    "heatmap_data = weekly_sentiment.pivot(index=\"country\", columns=\"week\", values=\"mean_sent\")\n",
    "\n",
    "# Optional: convert week to string for better labeling\n",
    "heatmap_data.columns = heatmap_data.columns.astype(str)\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"RdYlGn\",\n",
    "    vmin=0,\n",
    "    vmax=4.5,\n",
    "    annot=False,\n",
    "    cbar_kws={'label':'Average Sentiment'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray'\n",
    ")\n",
    "plt.title(f\"Fig. 3, Weekly Average Sentiment Heatmap — '{category}', RS, HR, HU, {custom_start} - {custom_end}\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87926d0d",
   "metadata": {},
   "source": [
    "*Figure 3 highlights that Serbia's sharp drop, the big gab in the data and subsequent recovery of sentiment in weekly sentiment on 'Health' debates is unique in this cross-country comparison. There are also gaps in the Hungary (HU) and Croatia (HR) datasets but it is likely that these reflect the annual parliamentary summer break. Prior to this, both countries exhibit consistently negative discussions on health. Croatia's parliament shows more fluctuations between positive and negative sentiment, while Hungary maintains a persistently negative baseline, with a pronounced drop in late winter 2021. This drop coincides with the second wave of COVID-19 and rising case numbers and deaths, which likely contributed to the heightened negativity in parliamentary speeches. To confirm this theory, a closer look into the actual parliamentary speeches, e.g. a keyword analysis, might be necessary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b45f60",
   "metadata": {},
   "source": [
    "In the next part of the tutorial, we will shift our focus from **sentiment analysis** - how parliaments reacted emotionally to major events like the COVID-19 pandemic - to **topic attention**, that is, how much speech was devoted to specific topics and how has this changed over time? This approach will help answer questions such as:\n",
    "\n",
    "**5. How did attention to 'Health' evolve in Serbia, Hungary and Croatia?**\n",
    "\n",
    "In order to reply to this question we define the right CAP category and the countries we want to investigate in the first part of our code (below). Then we have to make sure that the 'date' column in our DataFrame 'filtered_all_custom' is treated as actual dates ('datetime') instead of text. Then we create a new column called 'week', which groups all speeches by the week they were delivered. \n",
    "After that we sum up the **total numbers of words spoken** about the chosen topic for each country and each week. Then, the data is reshaped so that **countries become rows** and **weeks become columns**. Additionally, normalize the weekly word counts by dividing each week's word counts by the total for that week across all countries. This prevents a country with a generally larger parliament from dominating the chart. Finally, we create a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Choose the CAP category and countries to focus on ----\n",
    "category = \"Health\"  # <-- change to any CAP category you want\n",
    "countries_to_plot = [\"RS\", \"HR\", \"HU\"]  # <-- change or add countries here\n",
    "\n",
    "# ---- 2. Filter the dataset for the chosen category and countries ----\n",
    "category_df = filtered_all_custom[\n",
    "    (filtered_all_custom[\"CAP_category\"] == category) &\n",
    "    (filtered_all_custom[\"country\"].isin(countries_to_plot))\n",
    "].copy()\n",
    "\n",
    "# ---- 3. Make sure 'date' is datetime and create 'week' column ----\n",
    "category_df['date'] = pd.to_datetime(category_df['date'], errors='coerce')\n",
    "category_df['week'] = category_df['date'].dt.to_period('W').astype(str)\n",
    "\n",
    "# ---- 4. Group by country + week and sum word counts ----\n",
    "weekly_wordcount = (\n",
    "    category_df\n",
    "    .groupby(['country', 'week'])['word_count']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ---- 5. Pivot to get countries as rows, weeks as columns ----\n",
    "heatmap_data = weekly_wordcount.pivot(index='country', columns='week', values='word_count').fillna(0)\n",
    "\n",
    "# ---- 6. Ensure numeric dtype ----\n",
    "heatmap_data = heatmap_data.fillna(0).astype(float)\n",
    "\n",
    "# ---- 7. Normalize per week for fair cross-country comparison ----\n",
    "heatmap_data_norm = heatmap_data.div(heatmap_data.sum(axis=0), axis=1)\n",
    "\n",
    "# ---- 8. Plot the heatmap ----\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(\n",
    "    heatmap_data_norm,\n",
    "    cmap=\"YlGnBu\",\n",
    "    cbar_kws={'label': f'Relative Attention to {category}'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    annot=False\n",
    ")\n",
    "plt.title(f\"Fig. 4, Weekly Attention to '{category}' Across Selected Countries ({countries_to_plot})\", fontsize=14)\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd4ca2",
   "metadata": {},
   "source": [
    "*Figure 4 shows that the Hungarian parliament consistently devoted the most attention to the 'Health' topic among the three selected countries, with particularly strong activity in the first half and autumn of 2020. Croatia’s parliament also exhibits noticeable spikes in discussion on health during the same periods. Overall, both Hungary and Croatia display higher levels of attention to this topic than Serbia throughout the year.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea22a1b",
   "metadata": {},
   "source": [
    "**6. Conclusion**\n",
    "\n",
    "In this tutorial, we examined parliamentary debates **over time** from two perspectives:\n",
    "1) **Sentiment**: Weekly average sentiment can highlight how events (like COVID-19) shaped emotional tone. This can reflect in sharp drops or a prolonged negative baseline, as we saw in 'Health' debates. The cross-country comparisons revealed differences in how much sentiment fluctuates and how strongly opinions were expressed. \n",
    "2) **Topic attention**: Weekly word counts showed which parliaments focused most on specific topics. Hungary consistently emphasized 'Health', Croatia had spikes at key moment, and Serbia's attention remained lower.\n",
    "\n",
    "Together, these analyses demonstrate how tracking sentiment and attention over time provides insights into both **what parliaments discussed** and **how intensely they engages** with each topic.\n",
    "\n",
    "In the next tutorial (5), we will build on all previous tutorials by looking at the coalition-opposition behavior across all parliament to uncover structural patterns in their behavior. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praksa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
